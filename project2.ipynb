{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "السؤال الاول : عمليات preproses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "import os \n",
    "import pandas as pd\n",
    "import pickle \n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', 'are', 'running', 'quickly']\n"
     ]
    }
   ],
   "source": [
    "class Preprocessor():\n",
    "  \n",
    "  \n",
    "  @staticmethod\n",
    "  def process(doc):\n",
    "        s = doc\n",
    "        s = Preprocessor.remove_unwanted_characters(s)\n",
    "        s = Preprocessor.normalize_text(s)\n",
    "        s = Preprocessor.correct_spelling(s)\n",
    "        s = Preprocessor.lemmerDocument(s)\n",
    "        return s  \n",
    "  @staticmethod\n",
    "  def tokenizeDocument(sentence) :\n",
    "      \n",
    "     return word_tokenize(sentence)\n",
    "  \n",
    "  @staticmethod\n",
    "  def lemmerDocument(sentence):\n",
    "      lemmatizer = WordNetLemmatizer()\n",
    "      tokens = Preprocessor.tokenizeDocument(sentence)\n",
    "      return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "   \n",
    "  @staticmethod\n",
    "  def stemDocument(sentence):\n",
    "       stemmer = PorterStemmer()\n",
    "       tokens = Preprocessor.tokenizeDocument(sentence)\n",
    "       return [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    \n",
    "  @staticmethod \n",
    "  def rmvstpwrds(sentence):\n",
    "        terms=[]   \n",
    "        stopWords= set(stopwords.words('english'))\n",
    "        for term in sentence.split() :\n",
    "            if term not in stopWords :\n",
    "                terms.append(term)\n",
    "        return terms\n",
    "    \n",
    "  @staticmethod\n",
    "  def remove_unwanted_characters(sentence):\n",
    "        \n",
    "        return re.sub(r'[^a-zA-Z\\s]', '', sentence)    \n",
    "      \n",
    "      \n",
    "  @staticmethod\n",
    "  def normalize_text(sentence):\n",
    "        \n",
    "        return sentence.lower()\n",
    "    \n",
    "    \n",
    "  @staticmethod\n",
    "  def correct_spelling(sentence):\n",
    "       \n",
    "        spell = Speller()\n",
    "        \n",
    "        return ' '.join([spell(word) for word in sentence.split()])  \n",
    "    \n",
    "sentence=\"the cats are running quickly\"  \n",
    "lemmatized_sentence = Preprocessor.process(sentence)\n",
    "print(lemmatized_sentence) \n",
    "   \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "المهمة الثانية : انشاء نظام الاسترجاع "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexModel:\n",
    "    def __init__(self, documents_df=None, index_file=None, meta_file=None):\n",
    "        if index_file is None and meta_file is None and documents_df is not None:\n",
    "            self.create_new_index(documents_df)\n",
    "        elif index_file is not None and meta_file is not None:\n",
    "            self.read_index(index_file, meta_file)\n",
    "        else:\n",
    "            raise ValueError(\"Provide either documents_df for creating a new index or index_file and meta_file for reading an existing index\")\n",
    "\n",
    "    def create_new_index(self, documents_df):\n",
    "        termdoc = documents_df.to_dict('list')\n",
    "        unique_terms = set()\n",
    "        doc_ids = termdoc['id']\n",
    "\n",
    "        for terms in termdoc['ntext']:\n",
    "            unique_terms.update(terms)\n",
    "\n",
    "        term_ids = sorted(list(unique_terms))\n",
    "        term_to_id = {term: idx for idx, term in enumerate(term_ids)}\n",
    "        doc_to_id = {doc_id: idx for idx, doc_id in enumerate(doc_ids)}\n",
    "\n",
    "        self._index_matrix = [[0 for _ in range(len(doc_ids))] for _ in range(len(term_ids))]\n",
    "\n",
    "        for i, terms in enumerate(termdoc['ntext']):\n",
    "            for term in terms:\n",
    "                term_idx = term_to_id[term]\n",
    "                doc_idx = doc_to_id[doc_ids[i]]\n",
    "                self._index_matrix[term_idx][doc_idx] = 1\n",
    "\n",
    "        self._term_to_id = term_to_id\n",
    "        self._doc_to_id = doc_to_id\n",
    "\n",
    "    def get_term_vector(self, term):\n",
    "        if term in self._term_to_id:\n",
    "            term_idx = self._term_to_id[term]\n",
    "            return self._index_matrix[term_idx]\n",
    "        else:\n",
    "            return [0 for _ in range(len(self._doc_to_id))]\n",
    "\n",
    "    def read_index(self, index_file, meta_file):\n",
    "        with open(index_file, 'rb') as f:\n",
    "            self._index_matrix = pickle.load(f)\n",
    "\n",
    "        with open(meta_file, 'rb') as f:\n",
    "            meta_data = pickle.load(f)\n",
    "\n",
    "        self._term_to_id = meta_data['term_to_id']\n",
    "        self._doc_to_id = meta_data['doc_to_id']\n",
    "\n",
    "    def save_index(self, index_path, meta_path):\n",
    "        with open(index_path, 'wb') as f:\n",
    "            pickle.dump(self._index_matrix, f)\n",
    "\n",
    "        meta_data = {'term_to_id': self._term_to_id, 'doc_to_id': self._doc_to_id}\n",
    "        with open(meta_path, 'wb') as f:\n",
    "            pickle.dump(meta_data, f)\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self):\n",
    "        self._terms_operator = ['&', '|', '~']\n",
    "\n",
    "    def boolean_operator_processing(self, bop, prevV, nextV=None):\n",
    "        if bop == \"&\":\n",
    "            return [a & b for a, b in zip(prevV, nextV)]\n",
    "        elif bop == \"|\":\n",
    "            return [a | b for a, b in zip(prevV, nextV)]\n",
    "        elif bop == \"~\":\n",
    "            return [1 - a for a in prevV]\n",
    "\n",
    "    def retrieve(self, query_terms, index_model):\n",
    "        ret_docs = []\n",
    "        bitwiseop = \"\"\n",
    "        result = []\n",
    "        has_previous_term = False\n",
    "        has_not_operation = False\n",
    "        inc_vec_prev = []\n",
    "        inc_vec_next = []\n",
    "\n",
    "        for term in query_terms:\n",
    "            if term not in self._terms_operator:\n",
    "                if has_not_operation:\n",
    "                    if has_previous_term:\n",
    "                        inc_vec_next = self.boolean_operator_processing(\"~\", index_model.get_term_vector(term), inc_vec_next)\n",
    "                    else:\n",
    "                        inc_vec_prev = self.boolean_operator_processing(\"~\", index_model.get_term_vector(term), inc_vec_next)\n",
    "                        result = inc_vec_prev\n",
    "                    has_not_operation = False\n",
    "                elif has_previous_term:\n",
    "                    inc_vec_next = index_model.get_term_vector(term)\n",
    "                else:\n",
    "                    inc_vec_prev = index_model.get_term_vector(term)\n",
    "                    result = inc_vec_prev\n",
    "                    has_previous_term = True\n",
    "            elif term == \"~\":\n",
    "                has_not_operation = True\n",
    "            else:\n",
    "                bitwiseop = term\n",
    "\n",
    "            if len(inc_vec_next) != 0:\n",
    "                result = self.boolean_operator_processing(bitwiseop, inc_vec_prev, inc_vec_next)\n",
    "                inc_vec_prev = result\n",
    "                has_previous_term = True\n",
    "                inc_vec_next = []\n",
    "\n",
    "        for i, res in enumerate(result):\n",
    "            if res == 1:\n",
    "                ret_docs.append({'id': i, 'score': res})\n",
    "        ret_docs = pd.DataFrame(ret_docs, columns=['id', 'score']).sort_values(by=['score'], ascending=False)\n",
    "        return ret_docs\n",
    "\n",
    "class SearchEngine:\n",
    "    def __init__(self, preprocessor, retriever, documents, index_file=None, meta_file=None):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.retriever = retriever\n",
    "        self.documents = None\n",
    "        self.model = None\n",
    "        self.rebuild(documents, index_file, meta_file)\n",
    "\n",
    "    def rebuild(self, documents, index_file=None, meta_file=None):\n",
    "        self.documents = documents\n",
    "        self.documents['ntext'] = self.documents['text'].apply(self.preprocessor.process)\n",
    "        \n",
    "        if index_file and meta_file and os.path.exists(index_file) and os.path.exists(meta_file):\n",
    "            self.model = IndexModel(index_file=index_file, meta_file=meta_file)\n",
    "            print(f\"Index loaded from {index_file}\")\n",
    "            print(f\"Meta data loaded from {meta_file}\")\n",
    "        else:\n",
    "            self.model = IndexModel(documents_df=documents)\n",
    "            if index_file and meta_file:\n",
    "                self.model.save_index(index_file, meta_file)\n",
    "                print(f\"Index saved to {index_file}\")\n",
    "                print(f\"Meta data saved to {meta_file}\")\n",
    "\n",
    "    def querying(self, query):\n",
    "        query_terms = self.preprocessor.process(query)\n",
    "        term_vectors = [self.model.get_term_vector(term) for term in query_terms]\n",
    "\n",
    "        if not term_vectors:\n",
    "            return pd.DataFrame(columns=['id', 'score', 'content'])\n",
    "\n",
    "        scores = [sum(doc_scores) for doc_scores in zip(*term_vectors)]\n",
    "        results = [{'id': i, 'score': score, 'content': self.documents.iloc[i]['text']} for i, score in enumerate(scores) if score > 0]\n",
    "        results_df = pd.DataFrame(results).sort_values(by='score', ascending=False)\n",
    "        return results_df\n",
    "\n",
    "    def display_documents(self):\n",
    "        return self.documents[['id', 'ntext']]\n",
    "\n",
    "def loadDocuments(directory):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "                doc_id = len(documents)\n",
    "                content = file.read()\n",
    "                documents.append({'id': doc_id, 'text': content})\n",
    "    return pd.DataFrame(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_directory = 'project1_datacoll'\n",
    "documents_df = loadDocuments(documents_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_file_path = 'myindex.index'\n",
    "meta_file_path = 'idim.meta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index loaded from myindex.index\n",
      "Meta data loaded from idim.meta\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ntext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[if, you, want, to, go, fast, go, alone, if, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[a, successful, team, is, a, group, of, many, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[a, team, is, like, a, pack, of, wolvesalways,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[alone, we, can, do, so, little, together, we,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[coming, together, is, a, beginning, keeping, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              ntext\n",
       "0   0  [if, you, want, to, go, fast, go, alone, if, y...\n",
       "1   1  [a, successful, team, is, a, group, of, many, ...\n",
       "2   2  [a, team, is, like, a, pack, of, wolvesalways,...\n",
       "3   3  [alone, we, can, do, so, little, together, we,...\n",
       "4   4  [coming, together, is, a, beginning, keeping, ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_engine = SearchEngine(Preprocessor(), Retriever(), documents_df, index_file=index_file_path, meta_file=meta_file_path)\n",
    "\n",
    "processed_documents = search_engine.display_documents()\n",
    "processed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿If you want to go fast, go alone. If you want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿A team is like a pack of wolves—always hungry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿Coming together is a beginning. Keeping toget...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  score                                            content\n",
       "0   0      1  ﻿If you want to go fast, go alone. If you want...\n",
       "1   2      1  ﻿A team is like a pack of wolves—always hungry...\n",
       "2   4      1  ﻿Coming together is a beginning. Keeping toget..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_engine.querying(\"success fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>﻿Coming together is a beginning. Keeping toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿If you want to go fast, go alone. If you want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿A team is like a pack of wolves—always hungry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿Alone, we can do so little; together, we can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  score                                            content\n",
       "3   4      2  ﻿Coming together is a beginning. Keeping toget...\n",
       "0   0      1  ﻿If you want to go fast, go alone. If you want...\n",
       "1   2      1  ﻿A team is like a pack of wolves—always hungry...\n",
       "2   3      1  ﻿Alone, we can do so little; together, we can ..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_engine.querying(\"success together\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>fast success 💪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>teemwrk feelures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>success v.s failure?????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>qoates about success and cooperations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>funnyyyy teamss prgress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                  query\n",
       "0    1                         fast success 💪\n",
       "1    2                       teemwrk feelures\n",
       "2    3               success v.s failure?????\n",
       "3    4  qoates about success and cooperations\n",
       "4    5                funnyyyy teamss prgress"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df = pd.read_excel('Project1_Queries_Qrels.xlsx')\n",
    "queries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'get_qrels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17688\\1511481118.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mqrels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueries_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_qrels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mqrels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_qrels'"
     ]
    }
   ],
   "source": [
    "qrels = queries_df.get_qrels()\n",
    "qrels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "(\"Pyterrier requires Java 11 or newer, we only found Java version %s; install a more recent Java, or change os.environ['JAVA_HOME'] to point to the proper Java installation\", '1.8.0_241')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyterrier\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pt\u001b[38;5;241m.\u001b[39mstarted():\u001b[38;5;66;03m# this code for checking if jvm is working, if not\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m    \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyterrier\\__init__.py:133\u001b[0m, in \u001b[0;36minit\u001b[1;34m(version, mem, packages, jvm_opts, redirect_io, logging, home_dir, boot_packages, tqdm, no_download, helper_version)\u001b[0m\n\u001b[0;32m    131\u001b[0m java_version \u001b[38;5;241m=\u001b[39m autoclass(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava.lang.System\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgetProperty(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava.version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m java_version\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m java_version\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyterrier requires Java 11 or newer, we only found Java version \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m install a more recent Java, or change os.environ[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJAVA_HOME\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] to point to the proper Java installation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    135\u001b[0m         java_version)\n\u001b[0;32m    137\u001b[0m tr_version \u001b[38;5;241m=\u001b[39m autoclass(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg.terrier.Version\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    138\u001b[0m version_string \u001b[38;5;241m=\u001b[39m tr_version\u001b[38;5;241m.\u001b[39mVERSION\n",
      "\u001b[1;31mRuntimeError\u001b[0m: (\"Pyterrier requires Java 11 or newer, we only found Java version %s; install a more recent Java, or change os.environ['JAVA_HOME'] to point to the proper Java installation\", '1.8.0_241')"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():# this code for checking if jvm is working, if not\n",
    "   pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'br' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m queries \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess together\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess fast\u001b[39m\u001b[38;5;124m\"\u001b[39m]], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m \u001b[43mbr\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(queries)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'br' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "queries = pd.DataFrame([[\"q1\", \"success together\"], [\"q2\", \"success fast\"]], columns=[\"qid\", \"query\"])\n",
    "br.transform(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = pt.Utils.evaluate(tf_res,qrels[['qid','docno','label']],\n",
    "                         metrics=[\"map\",\"recall\",\"P\"])\n",
    "eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
